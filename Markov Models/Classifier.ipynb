{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames =['edgar_allan_poe.txt',\n",
    "            'robert_frost.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 belongs to edgar_allan_poe.txt\n",
      "1 belongs to robert_frost.txt\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "strings = []\n",
    "for label,files in enumerate(filenames):\n",
    "    print(f'{label} belongs to {files}')\n",
    "\n",
    "    for line in open(files):\n",
    "        line = line.lower().rstrip()\n",
    "        if line:\n",
    "            line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "            labels.append(label)\n",
    "            strings.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(strings, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "word2idx = {'<unk>':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in x_train:\n",
    "    tokens = x.split()\n",
    "    for token in tokens:\n",
    "        if token not in word2idx:\n",
    "            word2idx[token] = idx\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_int_list = []\n",
    "test_int_list = []\n",
    "for x in x_train:\n",
    "    tokens = x.split()\n",
    "    train_line = [word2idx[token] for token in tokens]\n",
    "    train_int_list.append(train_line)\n",
    "\n",
    "for x_1 in x_test:\n",
    "    tokens = x_1.split()\n",
    "    test_line = [word2idx.get(token, 0) for token in tokens]\n",
    "    test_int_list.append(test_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = len(word2idx)\n",
    "A0 = np.ones((v,v))\n",
    "pie0 = np.zeros(v)\n",
    "\n",
    "A1 = np.ones((v,v))\n",
    "pie1 = np.zeros(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updating_values(text_as_int, A, pie):\n",
    "    for tokens in text_as_int:\n",
    "        last_idx = None\n",
    "        for idx in tokens:\n",
    "            if last_idx==None:\n",
    "                pie[idx] += 1\n",
    "            else:\n",
    "                A[last_idx, idx] += 1\n",
    "            last_idx = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "updating_values([t for t,y in zip(train_int_list, y_train) if y==0], A0, pie0)\n",
    "updating_values([t for t,y in zip(train_int_list, y_train) if y==1], A1, pie1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0 /= A0.sum(axis=1, keepdims=True)\n",
    "A1 /= A1.sum(axis=1, keepdims=True)\n",
    "\n",
    "pie0 /= pie0.sum()\n",
    "pie1 /= pie1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7s/l0zcvrtx5vq4cfmpgm86sdhw0000gn/T/ipykernel_17470/2968328613.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  logpie0 = np.log(pie0)\n",
      "/var/folders/7s/l0zcvrtx5vq4cfmpgm86sdhw0000gn/T/ipykernel_17470/2968328613.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  logpie1 = np.log(pie1)\n"
     ]
    }
   ],
   "source": [
    "logA0 = np.log(A0)\n",
    "logA1 = np.log(A1)\n",
    "\n",
    "logpie0 = np.log(pie0)\n",
    "logpie1 = np.log(pie1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count0 = sum(y==0 for y in y_train)\n",
    "count1 = sum(y==1 for y in y_train)\n",
    "\n",
    "total = len(y_train)\n",
    "\n",
    "logprior0 = np.log(count0/total)\n",
    "logprior1 = np.log(count1/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, logAs, logpies, logpriors):\n",
    "        self.logAs = logAs\n",
    "        self.logpies = logpies\n",
    "        self.logpriors = logpriors\n",
    "        self.k = len(logpriors)\n",
    "\n",
    "    def _compute_log_likelihood(self, input_, class_):\n",
    "        logA = self.logAs[class_]\n",
    "        logpie = self.logpies[class_]\n",
    "\n",
    "        last_idx = None\n",
    "        logprob = 0\n",
    "        for idx in input_:\n",
    "            if last_idx == None:\n",
    "                logprob += logpie[idx]\n",
    "            else:\n",
    "                logprob += logA[last_idx, idx]\n",
    "            last_idx = idx\n",
    "        return logprob\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        predictions = np.zeros(len(inputs))\n",
    "        for i,input_ in enumerate(inputs):\n",
    "            posterior = [self._compute_log_likelihood(input_, c) + self.logpriors[c] for c in range(self.k)]\n",
    "            pred = np.argmax(posterior)\n",
    "            predictions[i] = pred\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9970980847359258\n"
     ]
    }
   ],
   "source": [
    "clf = Classifier([logA0, logA1], [logpie0, logpie1], [logprior0, logprior1])\n",
    "ptrain = clf.predict(train_int_list)\n",
    "print(f'Accuracy: {np.mean(ptrain==y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7517401392111369\n"
     ]
    }
   ],
   "source": [
    "ptest = clf.predict(test_int_list)\n",
    "print(f'Accuracy: {np.mean(ptest==y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7981366459627328"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, ptest)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
